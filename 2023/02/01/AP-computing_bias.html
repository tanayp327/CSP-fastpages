<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Big Idea 5.3 Computing Bias | Tanay Patel’s FastPages</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Big Idea 5.3 Computing Bias" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="This tech talk discusses bias in computing" />
<meta property="og:description" content="This tech talk discusses bias in computing" />
<link rel="canonical" href="https://tanayp327.github.io/CSP-fastpages/2023/02/01/AP-computing_bias.html" />
<meta property="og:url" content="https://tanayp327.github.io/CSP-fastpages/2023/02/01/AP-computing_bias.html" />
<meta property="og:site_name" content="Tanay Patel’s FastPages" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2023-02-01T00:00:00-06:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Big Idea 5.3 Computing Bias" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2023-02-01T00:00:00-06:00","datePublished":"2023-02-01T00:00:00-06:00","description":"This tech talk discusses bias in computing","headline":"Big Idea 5.3 Computing Bias","mainEntityOfPage":{"@type":"WebPage","@id":"https://tanayp327.github.io/CSP-fastpages/2023/02/01/AP-computing_bias.html"},"url":"https://tanayp327.github.io/CSP-fastpages/2023/02/01/AP-computing_bias.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/CSP-fastpages/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://tanayp327.github.io/CSP-fastpages/feed.xml" title="Tanay Patel's FastPages" /><link rel="shortcut icon" type="image/x-icon" href="/CSP-fastpages/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />

<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/CSP-fastpages/">Tanay Patel&#39;s FastPages</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/CSP-fastpages/notes/">CSP Notes</a><a class="page-link" href="/CSP-fastpages/submenu/">Submenu</a><a class="page-link" href="/CSP-fastpages/about/">About Me</a><a class="page-link" href="/CSP-fastpages/search/">Search</a><a class="page-link" href="/CSP-fastpages/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Big Idea 5.3 Computing Bias</h1><p class="page-description">This tech talk discusses bias in computing</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2023-02-01T00:00:00-06:00" itemprop="datePublished">
        Feb 1, 2023
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      3 min read
    
</span></p>

    

    </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul id="toc" class="section-nav">
<li class="toc-entry toc-h1"><a href="#computer-bias">Computer Bias</a>
<ul>
<li class="toc-entry toc-h3"><a href="#intentional-or-purposeful-bias-crossover-group-up-10-minutes">Intentional or Purposeful bias (Crossover Group Up, 10 minutes)</a></li>
<li class="toc-entry toc-h3"><a href="#as-pairs-5-minutes">As Pairs (5 minutes)</a></li>
<li class="toc-entry toc-h2"><a href="#hacks">Hacks</a></li>
</ul>
</li>
</ul><h1 id="computer-bias">
<a class="anchor" href="#computer-bias" aria-hidden="true"><span class="octicon octicon-link"></span></a>Computer Bias</h1>
<p>Earlier we talked about beneficial and harmful effects of computing.  Such conversation often lead to conversations on computer bias, particularly when bias creates a harmful effect.</p>

<p>As programmers, you now have the possibility of creating algorithms.  It has been said, “Humans are error-prone and biased”.  So, does that mean algorithms and the computers they run on are better?</p>

<h3 id="intentional-or-purposeful-bias-crossover-group-up-10-minutes">
<a class="anchor" href="#intentional-or-purposeful-bias-crossover-group-up-10-minutes" aria-hidden="true"><span class="octicon octicon-link"></span></a>Intentional or Purposeful bias (Crossover Group Up, 10 minutes)</h3>
<ul>
  <li>Google “What age groups use Facebook” vs “… TikTok”?  What does the data say?  Is there purposeful exclusion in these platforms?  Is it harmful?  Should it be corrected?  Is it good business?
41.7% of Facebook’s audience are 18-34 years old. The data also says that 62% of TikTok’s users are 10-29 years old. There isn’t purposeful exclusion on these platforms, but the different types of content appeals to different people. I don’t think it is harmful because everyone is free to sign up for whichever platform they want.</li>
  <li>Why do virtual assistants have female voices? Amazon, Alexa Google, Apple Siri. Was this purposeful?  Is it harmful?  Should it be corrected?  Is it good business?
Virtual assistants have female voices because females are commonly perceived as more freindly and helpful. I personally dont think this is harmful, but some children may beleive that this means that females are just assistants.</li>
  <li>Talk about an algorithm that influences your decisions, think about these companies (ie FAANG - Facebook, Amazon, Apple,Netflix, Google)
The YouTube algorithm uses my previously watched videos as well as data from other websites to influence what I watch and might cause me to spend more time on YouTube.</li>
</ul>

<h3 id="as-pairs-5-minutes">
<a class="anchor" href="#as-pairs-5-minutes" aria-hidden="true"><span class="octicon octicon-link"></span></a>As Pairs (5 minutes)</h3>
<ul>
  <li>Watch the video… <a href="https://www.youtube.com/watch?v=t4DT3tQqgRM">HP computers are racist</a>
</li>
  <li>Come up with some thoughts on the video and be ready to discuss them as I call on you.  Here are some ideas…
    <ul>
      <li>Does the owner of the computer think this was intentional?
  Based on the owner’s joking tone in the video, he probably understands that it likely wasn’t intentional, but he understandably upset by the flaw.</li>
      <li>If yes or no, justify your conclusion.
  His tone in the video wasn’t as serious as someone that thought HP was being intentionally racist.</li>
      <li>How do you think this happened?
  I think this happened because they didn’t test their software on anyone with dark colored skin, so they didn’t know that the software didnt work as intended.</li>
      <li>Is this harmful?  Was it intended to be harmful or exclude?
  This can be potentially harmful because of the fact that people with dark skin are excluded, although it wasn’t intended to be harmful.</li>
      <li>Should it be corrected?
  Yes, it should definitely be corrected. Everyone should be able to have equal opportunity wiht technology no matter of their race.</li>
      <li>What would you or should you do to produce a better outcome?
  Make sure that all different groups of people are involved in the testing process.</li>
    </ul>
  </li>
</ul>

<h2 id="hacks">
<a class="anchor" href="#hacks" aria-hidden="true"><span class="octicon octicon-link"></span></a>Hacks</h2>
<blockquote>
  <p>Write summary/thoughts/conclusions from each of the exercises above.  Focus on avoiding Bias in algorithms or code you write.
We learned about computing bias, which is when computer systems unfairly discriminate against certain types of people. I think that seeing what happened with the person with an HP computer shows that a lack of testing can be very detrimental. I think that for what we’re doing right now, computer bias isn’t very likely to happen, but we should keep in mind that there are different types of people that we need to consider when testing.</p>
</blockquote>

  </div><a class="u-url" href="/CSP-fastpages/2023/02/01/AP-computing_bias.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/CSP-fastpages/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="https://tanayp327.github.io/CSP-fastpages/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/CSP-fastpages/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>My FastPages Website.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"></ul>
</div>

  </div>

</footer>
</body>

</html>
